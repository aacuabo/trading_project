import streamlit as st
import pandas as pd
from sqlalchemy import create_engine
from datetime import datetime, date
import altair as alt
import plotly.graph_objects as go # Added for Sankey chart

# Set Streamlit page configuration
st.set_page_config(layout="wide") # Use wide layout for better display

# --- DATABASE CONFIGURATION ---
@st.cache_resource # Cache the database engine creation
def get_sqlalchemy_engine():
Â  Â  """Establishes and returns a SQLAlchemy database engine using Streamlit secrets."""
Â  Â  try:
Â  Â  Â  Â  user = st.secrets["database"]["user"]
Â  Â  Â  Â  password = st.secrets["database"]["password"]
Â  Â  Â  Â  host = st.secrets["database"]["host"]
Â  Â  Â  Â  db = st.secrets["database"]["db"]
Â  Â  Â  Â  port = int(st.secrets["database"]["port"])
Â  Â  Â  Â  url = f"postgresql+psycopg2://{user}:{password}@{host}:{port}/{db}"
Â  Â  Â  Â  engine = create_engine(url, pool_pre_ping=True)
Â  Â  Â  Â  return engine
Â  Â  except KeyError as e:
Â  Â  Â  Â  st.error(f"Error loading database credentials: {e}. Make sure your .streamlit/secrets.toml file is correctly configured with [database] section and keys: user, password, host, db, port.")
Â  Â  Â  Â  st.stop()
Â  Â  except ValueError:
Â  Â  Â  Â  Â st.error("Error: Database port in secrets.toml is not a valid integer.")
Â  Â  Â  Â  Â st.stop()
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Error creating database engine: {e}")
Â  Â  Â  Â  st.stop()


# --- LOAD DATA ---
@st.cache_data(ttl=3600)
def fetch_available_dates():
Â  Â  """Fetches a list of unique dates available in the database."""
Â  Â  try:
Â  Â  Â  Â  engine = get_sqlalchemy_engine()
Â  Â  Â  Â  query = """
Â  Â  Â  Â  Â  Â  SELECT DISTINCT "Date"
Â  Â  Â  Â  Â  Â  FROM "MQ_Hourly"
Â  Â  Â  Â  Â  Â  ORDER BY "Date";
Â  Â  Â  Â  """
Â  Â  Â  Â  dates_df = pd.read_sql(query, engine, parse_dates=["Date"])
Â  Â  Â  Â  available_dates = dates_df["Date"].dt.date.tolist()
Â  Â  Â  Â  return available_dates
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Error fetching available dates: {e}")
Â  Â  Â  Â  return []


@st.cache_data(ttl=600)
def fetch_data(selected_date_str: str):
Â  Â  """Fetches hourly MQ, BCQ, and Prices data for a selected date."""
Â  Â  try:
Â  Â  Â  Â  engine = get_sqlalchemy_engine()
Â  Â  Â  Â  query = """
Â  Â  Â  Â  Â  Â  SELECT mq."Time", mq."Total_MQ", bcq."Total_BCQ", p."Prices"
Â  Â  Â  Â  Â  Â  FROM "MQ_Hourly" AS mq
Â  Â  Â  Â  Â  Â  JOIN "BCQ_Hourly" AS bcq ON mq."Date" = bcq."Date" AND mq."Time" = bcq."Time"
Â  Â  Â  Â  Â  Â  JOIN "Prices_Hourly" AS p ON mq."Date" = p."Date" AND mq."Time" = p."Time"
Â  Â  Â  Â  Â  Â  WHERE mq."Date" = %s
Â  Â  Â  Â  Â  Â  ORDER BY mq."Time";
Â  Â  Â  Â  """
Â  Â  Â  Â  # parse_dates cannot parse 'Time' directly if it's just a time string without a date
Â  Â  Â  Â  # It's better to combine date and time after fetching if 'Time' is just HH:MM:SS
Â  Â  Â  Â  df = pd.read_sql(query, engine, params=[(selected_date_str,)])

Â  Â  Â  Â  if not df.empty and 'Time' in df.columns:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  # Ensure 'Time' is string, extract time part if it's datetime.time, then combine
Â  Â  Â  Â  Â  Â  Â  Â  if pd.api.types.is_datetime64_any_dtype(df['Time']): # If already full datetime
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df['Datetime'] = df['Time']
Â  Â  Â  Â  Â  Â  Â  Â  elif pd.api.types.is_string_dtype(df['Time']):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df['Datetime'] = pd.to_datetime(selected_date_str + ' ' + df['Time'], errors='coerce')
Â  Â  Â  Â  Â  Â  Â  Â  else: # Attempt to convert to string then combine (e.g. if it's datetime.time object)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df['Time_str'] = df['Time'].astype(str).str.split().str[-1] # Get HH:MM:SS part
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df['Datetime'] = pd.to_datetime(selected_date_str + ' ' + df['Time_str'], errors='coerce')

Â  Â  Â  Â  Â  Â  Â  Â  df.dropna(subset=['Datetime'], inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  df['Time'] = df['Datetime'] # Replace original 'Time' with full datetime
Â  Â  Â  Â  Â  Â  Â  Â  df.drop(columns=['Datetime'], inplace=True, errors='ignore') # Clean up
Â  Â  Â  Â  Â  Â  Â  Â  df.drop(columns=['Time_str'], inplace=True, errors='ignore') # Clean up
Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Error converting 'Time' column to datetime after fetch: {e}. Check format.")
Â  Â  Â  Â  Â  Â  Â  Â  return pd.DataFrame()
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  if 'Time' not in df.columns: st.warning("Time column missing in fetched data.")


Â  Â  Â  Â  for col in ["Total_MQ", "Total_BCQ", "Prices"]:
Â  Â  Â  Â  Â  Â  if col in df.columns:
Â  Â  Â  Â  Â  Â  Â  Â  df[col] = pd.to_numeric(df[col], errors='coerce')
Â  Â  Â  Â  return df
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Error fetching data: {e}")
Â  Â  Â  Â  return pd.DataFrame()

# --- SANKEY CHART HELPER FUNCTIONS ---
# Define mappings as per comments in the prompt
GENERATOR_LONG_TO_SHORT_MAP = {
Â  Â  "FDC Misamis Power Corporation (FDC)": 'FDC',
Â  Â  "GNPower Kauswagan Ltd. Co. (GNPKLCO)": 'GNPK',
Â  Â  "Power Sector Assets & Liabilities Management Corporation (PSALMGMIN)": 'PSALM',
Â  Â  "Sarangani Energy Corporation (SEC)": 'SEC',
Â  Â  "Therma South, Inc. (TSI)": 'TSI',
Â  Â  "Malita Power Inc. (SMCPC)": 'MPI'
}

DESTINATION_LONG_TO_SHORT_MAP = {
Â  Â  "14BGN_T1L1_KIDCOTE01_NET": 'M1/M6/M8',
Â  Â  "14BGN_T1L1_KIDCOTE02_NET": 'M2',
Â  Â  "14BGN_T1L1_KIDCOTE03_NET": 'M3',
Â  Â  "14BGN_T1L1_KIDCOTE04_NET": 'M4',
Â  Â  "14BGN_T2L1_KIDCOTE05_NET": 'M5',
Â  Â  "14BGN_T1L1_KIDCOTE08_NET": 'M7',
Â  Â  "14BGN_T1L1_KIDCOTE10_NET": 'M9',
Â  Â  "14BGN_T1L1_KIDCSCV01_DEL": 'KIDCSCV01_DEL',
Â  Â  "14BGN_T1L1_KIDCSCV02_DEL": 'KIDCSCV02_DEL'
}

@st.cache_data(ttl=600)
def fetch_sankey_generator_contributions(selected_date_str: str, engine, gen_short_to_long_map: dict):
Â  Â  """
Â  Â  Fetches daily total contributions for each specified generator.
Â  Â  NOTE: This is a placeholder. You MUST implement the actual database query.
Â  Â  The query should sum up the daily energy (e.g., in kWh) for each generator.
Â  Â  The prompt mentioned '* 1000' for generators. If your DB stores in MWh,
Â  Â  you'd multiply by 1000 here to get kWh. This placeholder assumes kWh.
Â  Â  """
Â  Â  st.warning("Sankey Generator Data: Using DUMMY values. Implement actual DB query in `Workspace_sankey_generator_contributions`.")
Â  Â  contributions = {}
Â  Â  # Example: Query a table 'Generator_Daily_Output'
Â  Â  # query = """
Â  Â  # SELECT "GeneratorName", SUM("Output_kWh") as "TotalOutput"
Â  Â  # FROM "Generator_Daily_Output"
Â  Â  # WHERE "Date" = %s AND "GeneratorName" IN %s
Â  Â  # GROUP BY "GeneratorName";
Â  Â  # """
Â  Â  # df_gen = pd.read_sql(query, engine, params=[(selected_date_str, tuple(gen_short_to_long_map.keys()))])
Â  Â  # for _, row in df_gen.iterrows():
Â  Â  # contributions[gen_short_to_long_map[row["GeneratorName"]]] = row["TotalOutput"] * 1000 # If scaling needed

Â  Â  # Placeholder: Distribute a dummy total, or assign fixed values
Â  Â  dummy_total_generation = 500000 #kWh
Â  Â  num_generators = len(gen_short_to_long_map)
Â  Â  if num_generators > 0:
Â  Â  Â  Â  for i, short_name in enumerate(gen_short_to_long_map.values()):
Â  Â  Â  Â  Â  Â  # Assign pseudo-random looking values for better visual
Â  Â  Â  Â  Â  Â  contributions[short_name] = (dummy_total_generation / num_generators) * (1 + (i % 3 - 1) * 0.2)
Â  Â  return contributions


@st.cache_data(ttl=600)
def fetch_sankey_destination_consumption(selected_date_str: str, engine, dest_short_to_long_map: dict, total_mq_to_distribute: float):
Â  Â  """
Â  Â  Fetches or calculates the consumption for each specified destination.
Â  Â  NOTE: This is a placeholder. Ideally, you query actual consumption data.
Â  Â  If not available, it distributes total_mq_to_distribute among destinations.
Â  Â  """
Â  Â  st.warning("Sankey Destination Data: Using DUMMY proportional distribution. Implement DB query in `Workspace_sankey_destination_consumption`.")
Â  Â  consumption = {}
Â  Â  # Example: Query a table 'Destination_Daily_Consumption'
Â  Â  # query = """
Â  Â  # SELECT "DestinationNodeID", SUM("Consumption_kWh") as "TotalConsumption"
Â  Â  # FROM "Destination_Daily_Consumption"
Â  Â  # WHERE "Date" = %s AND "DestinationNodeID" IN %s
Â  Â  # GROUP BY "DestinationNodeID";
Â  Â  # """
Â  Â  # df_dest = pd.read_sql(query, engine, params=[(selected_date_str, tuple(dest_short_to_long_map.keys()))])
Â  Â  # for _, row in df_dest.iterrows():
Â  Â  # Â  Â  consumption[dest_short_to_long_map[row["DestinationNodeID"]]] = row["TotalConsumption"]

Â  Â  # Placeholder: Distribute total_mq_to_distribute proportionally (equally here)
Â  Â  num_destinations = len(dest_short_to_long_map)
Â  Â  if num_destinations > 0:
Â  Â  Â  Â  for i, short_name in enumerate(dest_short_to_long_map.values()):
Â  Â  Â  Â  Â  Â  consumption[short_name] = (total_mq_to_distribute / num_destinations) * (1 + (i % 3 - 1) * 0.1) # Slight variation
Â  Â  Â  Â  # Normalize to ensure sum matches total_mq_to_distribute if using variations
Â  Â  Â  Â  current_sum = sum(consumption.values())
Â  Â  Â  Â  if current_sum > 0 : # Avoid division by zero
Â  Â  Â  Â  Â  Â  scaling_factor = total_mq_to_distribute / current_sum
Â  Â  Â  Â  Â  Â  for short_name in consumption:
Â  Â  Â  Â  Â  Â  Â  Â  consumption[short_name] *= scaling_factor
Â  Â  return consumption


# --- STREAMLIT UI ---
st.title("ðŸ“Š Daily Energy Trading Dashboard")

spacer_left, main_content, spacer_right = st.columns([0.5, 4, 0.5]) # Adjusted spacer for potentially wider content

with main_content:
Â  Â  available_dates = fetch_available_dates()

Â  Â  if not available_dates:
Â  Â  Â  Â  st.error("No available dates found. Check database connection and data.")
Â  Â  Â  Â  st.stop()

Â  Â  min_available_date = min(available_dates)
Â  Â  max_available_date = max(available_dates)
Â  Â  default_date = max_available_date # Default to the latest available date

Â  Â  selected_date = st.date_input(
Â  Â  Â  Â  "Select date",
Â  Â  Â  Â  value=default_date,
Â  Â  Â  Â  min_value=min_available_date,
Â  Â  Â  Â  max_value=max_available_date,
Â  Â  )

Â  Â  if selected_date not in available_dates:
Â  Â  Â  Â  st.warning(f"Data may not be available for the exact date selected: {selected_date}. Displaying data for the closest available date or period if applicable.")

Â  Â  selected_date_str = selected_date.strftime('%Y-%m-%d')
Â  Â  data = fetch_data(selected_date_str)

Â  Â  if not data.empty:
Â  Â  Â  Â  st.subheader("Daily Summary Metrics")
Â  Â  Â  Â  col1, col2, col3 = st.columns(3)

Â  Â  Â  Â  if "Prices" in data.columns and not data["Prices"].empty and pd.api.types.is_numeric_dtype(data["Prices"]):
Â  Â  Â  Â  Â  Â  max_price = data["Prices"].max(skipna=True)
Â  Â  Â  Â  Â  Â  avg_price = data["Prices"].mean(skipna=True)
Â  Â  Â  Â  Â  Â  col1.metric(label="Maximum Price (PHP/kWh)", value=f"{max_price:,.2f}" if pd.notna(max_price) else "N/A")
Â  Â  Â  Â  Â  Â  col2.metric(label="Average Price (PHP/kWh)", value=f"{avg_price:,.2f}" if pd.notna(avg_price) else "N/A")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  col1.warning("Prices data not available/numeric.")
Â  Â  Â  Â  Â  Â  col2.warning("Avg Price data not available/numeric.")

Â  Â  Â  Â  if "Total_MQ" in data.columns and "Time" in data.columns and \
Â  Â  Â  Â  Â   not data["Total_MQ"].empty and pd.api.types.is_numeric_dtype(data["Total_MQ"]) and \
Â  Â  Â  Â  Â   not data["Total_MQ"].isnull().all():
Â  Â  Â  Â  Â  Â  max_mq_value = data["Total_MQ"].max(skipna=True)
Â  Â  Â  Â  Â  Â  if pd.notna(max_mq_value):
Â  Â  Â  Â  Â  Â  Â  Â  max_mq_row_index = data["Total_MQ"].idxmax()
Â  Â  Â  Â  Â  Â  Â  Â  max_mq_time = data.loc[max_mq_row_index, "Time"]
Â  Â  Â  Â  Â  Â  Â  Â  max_mq_time_str = max_mq_time.strftime("%H:%M") if pd.api.types.is_datetime64_any_dtype(max_mq_time) else str(max_mq_time)
Â  Â  Â  Â  Â  Â  Â  Â  col3.metric(label="Maximum Total MQ (kWh)", value=f"{max_mq_value:,.2f}")
Â  Â  Â  Â  Â  Â  Â  Â  col3.write(f"at {max_mq_time_str}")
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  col3.info("Total_MQ data is all NaN.")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  col3.warning("Max MQ/Time data not available/numeric or all null.")


Â  Â  Â  Â  if all(col in data.columns for col in ["Total_BCQ", "Total_MQ"]) and \
Â  Â  Â  Â  Â   pd.api.types.is_numeric_dtype(data["Total_BCQ"]) and pd.api.types.is_numeric_dtype(data["Total_MQ"]):
Â  Â  Â  Â  Â  Â  data['WESM'] = data['Total_BCQ'] - data['Total_MQ']
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.warning("WESM column not calculated: Total_BCQ or Total_MQ are missing or not numeric.")
Â  Â  Â  Â  Â  Â  data['WESM'] = pd.NA # Ensure column exists even if calculation fails for safety

Â  Â  Â  Â  st.subheader("Hourly Summary")
Â  Â  Â  Â  st.dataframe(data)

Â  Â  Â  Â  st.subheader("ðŸ“ˆ Energy Metrics Over Time (Interactive)")
Â  Â  Â  Â  if 'Time' in data.columns and pd.api.types.is_datetime64_any_dtype(data['Time']):
Â  Â  Â  Â  Â  Â  columns_to_melt = ["Total_MQ", "Total_BCQ", "Prices"]
Â  Â  Â  Â  Â  Â  existing_cols_to_melt = [col for col in columns_to_melt if col in data.columns and not data[col].isnull().all()]

Â  Â  Â  Â  Â  Â  if existing_cols_to_melt:
Â  Â  Â  Â  Â  Â  Â  Â  melted_data = data.melt(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  id_vars=["Time"],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value_vars=existing_cols_to_melt,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var_name="Metric",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value_name="Value"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  melted_data.dropna(subset=['Value'], inplace=True) # Drop rows where 'Value' became NaN

Â  Â  Â  Â  Â  Â  Â  Â  # Chart for MQ and BCQ
Â  Â  Â  Â  Â  Â  Â  Â  energy_metrics = [m for m in ["Total_MQ", "Total_BCQ"] if m in existing_cols_to_melt]
Â  Â  Â  Â  Â  Â  Â  Â  if energy_metrics:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  chart_energy = alt.Chart(melted_data[melted_data["Metric"].isin(energy_metrics)]).mark_line(point=True).encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X("Time:T", axis=alt.Axis(title="Time", format="%H:%M")),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y=alt.Y("Value:Q", title="Energy (kWh)", axis=alt.Axis(titleColor="#1A85FF"), scale=alt.Scale(zero=True)),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color=alt.Color("Metric:N", legend=alt.Legend(title="Metric", orient='bottom'),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  scale=alt.Scale(domain=['Total_MQ', 'Total_BCQ'], range=['#FFC20A', '#1A85FF'])),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=[alt.Tooltip("Time:T", format="%Y-%m-%d %H:%M"), "Metric:N", "Value:Q"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ).properties(title="Energy Metrics")
Â  Â  Â  Â  Â  Â  Â  Â  else: chart_energy = alt.Chart(pd.DataFrame()).mark_text() # Empty chart

Â  Â  Â  Â  Â  Â  Â  Â  # Chart for Prices
Â  Â  Â  Â  Â  Â  Â  Â  if "Prices" in existing_cols_to_melt:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  chart_price = alt.Chart(melted_data[melted_data["Metric"] == "Prices"]).mark_bar(color="#40B0A6").encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X("Time:T", axis=alt.Axis(title="Time", format="%H:%M")), # Keep x-axis title for bars if layered
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y=alt.Y("Value:Q", title="Price (PHP/kWh)", axis=alt.Axis(titleColor="#40B0A6"), scale=alt.Scale(zero=True)),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=[alt.Tooltip("Time:T", format="%Y-%m-%d %H:%M"), "Metric:N", "Value:Q"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ).properties(title="Prices")
Â  Â  Â  Â  Â  Â  Â  Â  else: chart_price = alt.Chart(pd.DataFrame()).mark_text() # Empty chart

Â  Â  Â  Â  Â  Â  Â  Â  # Combine charts
Â  Â  Â  Â  Â  Â  Â  Â  if energy_metrics and "Prices" in existing_cols_to_melt:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  combined_chart = alt.layer(chart_price, chart_energy).resolve_scale(y='independent').properties(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  title=f"Energy Metrics and Prices for {selected_date_str}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ).interactive()
Â  Â  Â  Â  Â  Â  Â  Â  elif energy_metrics: # Only energy chart
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  combined_chart = chart_energy.properties(title=f"Energy Metrics for {selected_date_str}").interactive()
Â  Â  Â  Â  Â  Â  Â  Â  elif "Prices" in existing_cols_to_melt: # Only price chart
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  combined_chart = chart_price.properties(title=f"Prices for {selected_date_str}").interactive()
Â  Â  Â  Â  Â  Â  Â  Â  else: # No data to plot
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  combined_chart = alt.Chart(pd.DataFrame()).mark_text(text="No data to plot for selected metrics.").properties(title="No Data")

Â  Â  Â  Â  Â  Â  Â  Â  st.altair_chart(combined_chart, use_container_width=True)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"Required columns for plotting are missing or all null in data for {selected_date_str}.")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.warning("Time column not in expected datetime format or data is empty.")


Â  Â  Â  Â  # --- SANKEY CHART ---
Â  Â  Â  Â  st.subheader("âš¡ Daily Energy Flow Sankey Chart")
Â  Â  Â  Â  if 'Total_MQ' in data.columns and 'WESM' in data.columns and \
Â  Â  Â  Â  Â   pd.api.types.is_numeric_dtype(data['Total_MQ']) and \
Â  Â  Â  Â  Â   pd.api.types.is_numeric_dtype(data['WESM']) and \
Â  Â  Â  Â  Â   not data['Total_MQ'].isnull().all():

Â  Â  Â  Â  Â  Â  engine = get_sqlalchemy_engine()
Â  Â  Â  Â  Â  Â  sankey_node_labels = []
Â  Â  Â  Â  Â  Â  node_indices = {} # To map label to index
Â  Â  Â  Â  Â  Â  sankey_sources_indices = []
Â  Â  Â  Â  Â  Â  sankey_targets_indices = []
Â  Â  Â  Â  Â  Â  sankey_values = []
Â  Â  Â  Â  Â  Â  node_colors = [] # For Plotly node colors

Â  Â  Â  Â  Â  Â  def add_node(label, color="grey"): # Helper to add unique nodes
Â  Â  Â  Â  Â  Â  Â  Â  if label not in node_indices:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  node_indices[label] = len(sankey_node_labels)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sankey_node_labels.append(label)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  node_colors.append(color) # Store color for this node index
Â  Â  Â  Â  Â  Â  Â  Â  return node_indices[label]

Â  Â  Â  Â  Â  Â  # 1. Middle Node: Total MQ
Â  Â  Â  Â  Â  Â  total_mq_sum = data['Total_MQ'].sum()
Â  Â  Â  Â  Â  Â  if pd.isna(total_mq_sum) or total_mq_sum == 0:
Â  Â  Â  Â  Â  Â  Â  Â  st.info(f"Total MQ is zero or N/A for {selected_date_str}. Cannot generate Sankey chart.")
Â  Â  Â  Â  Â  Â  Â  Â  # To prevent further execution in this block if total_mq_sum is not valid
Â  Â  Â  Â  Â  Â  Â  Â  display_sankey = False
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  display_sankey = True
Â  Â  Â  Â  Â  Â  Â  Â  middle_node_label = f"Total Daily MQ ({total_mq_sum:,.0f} kWh)"
Â  Â  Â  Â  Â  Â  Â  Â  middle_node_idx = add_node(middle_node_label, "orange")

Â  Â  Â  Â  Â  Â  Â  Â  # 2. Source Nodes (Generators & WESM)
Â  Â  Â  Â  Â  Â  Â  Â  # Generators
Â  Â  Â  Â  Â  Â  Â  Â  gen_short_to_long_map_inv = {v: k for k, v in GENERATOR_LONG_TO_SHORT_MAP.items()} # for dummy data fetch
Â  Â  Â  Â  Â  Â  Â  Â  generator_contributions = fetch_sankey_generator_contributions(selected_date_str, engine, GENERATOR_LONG_TO_SHORT_MAP)

Â  Â  Â  Â  Â  Â  Â  Â  for short_name, value in generator_contributions.items():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if value > 0: # Only add if there's a positive contribution
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # The prompt's '* 1000' for generators: apply if fetched data is e.g. MWh
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # scaled_value = value * 1000 # Apply scaling if necessary
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  scaled_value = value # Assuming fetched value is already in desired unit (e.g. kWh)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  gen_node_label = f"{short_name} ({scaled_value:,.0f} kWh)"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  gen_node_idx = add_node(gen_node_label, "blue")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sankey_sources_indices.append(gen_node_idx)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sankey_targets_indices.append(middle_node_idx)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sankey_values.append(scaled_value)

Â  Â  Â  Â  Â  Â  Â  Â  # WESM Contribution
Â  Â  Â  Â  Â  Â  Â  Â  wesm_daily_sum = data['WESM'].sum()
Â  Â  Â  Â  Â  Â  Â  Â  # Prompt: "Total WESM (from chart) * -1" as a SOURCE.
Â  Â  Â  Â  Â  Â  Â  Â  # Interpretation 1 (Strict): value = wesm_daily_sum * -1. If positive, use it.
Â  Â  Â  Â  Â  Â  Â  Â  # wesm_sankey_val_strict = wesm_daily_sum * -1
Â  Â  Â  Â  Â  Â  Â  Â  # if wesm_sankey_val_strict > 0:
Â  Â  Â  Â  Â  Â  Â  Â  # Â  Â  wesm_label = f"WESM (calc as export: {wesm_sankey_val_strict:,.0f} kWh)"
Â  Â  Â  Â  Â  Â  Â  Â  # Â  Â  wesm_node_idx = add_node(wesm_label, "red")
Â  Â  Â  Â  Â  Â  Â  Â  # Â  Â  sankey_sources_indices.append(wesm_node_idx)
Â  Â  Â  Â  Â  Â  Â  Â  # Â  Â  sankey_targets_indices.append(middle_node_idx)
Â  Â  Â  Â  Â  Â  Â  Â  # Â  Â  sankey_values.append(wesm_sankey_val_strict)

Â  Â  Â  Â  Â  Â  Â  Â  # Interpretation 2 (Standard for WESM as Source - Net Import):
Â  Â  Â  Â  Â  Â  Â  Â  if wesm_daily_sum > 0: # Net import from WESM
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  wesm_label = f"WESM Net Import ({wesm_daily_sum:,.0f} kWh)"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  wesm_node_idx = add_node(wesm_label, "red")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sankey_sources_indices.append(wesm_node_idx)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sankey_targets_indices.append(middle_node_idx)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sankey_values.append(wesm_daily_sum)
Â  Â  Â  Â  Â  Â  Â  Â  # If WESM is a net export (wesm_daily_sum < 0), it could be a destination.
Â  Â  Â  Â  Â  Â  Â  Â  # The prompt only lists it as a source, so we'll only consider net imports here.

Â  Â  Â  Â  Â  Â  Â  Â  # 3. Destination Nodes
Â  Â  Â  Â  Â  Â  Â  Â  # The sum of destination values should ideally equal total_mq_sum.
Â  Â  Â  Â  Â  Â  Â  Â  # fetch_sankey_destination_consumption should handle fetching/distributing this.
Â  Â  Â  Â  Â  Â  Â  Â  dest_short_to_long_map_inv = {v: k for k, v in DESTINATION_LONG_TO_SHORT_MAP.items()} # for dummy data
Â  Â  Â  Â  Â  Â  Â  Â  destination_consumptions = fetch_sankey_destination_consumption(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  selected_date_str, engine, DESTINATION_LONG_TO_SHORT_MAP, total_mq_sum
Â  Â  Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  Â  Â  for short_name, value in destination_consumptions.items():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if value > 0:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  dest_node_label = f"{short_name} ({value:,.0f} kWh)"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  dest_node_idx = add_node(dest_node_label, "green")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sankey_sources_indices.append(middle_node_idx) # Source is middle node
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sankey_targets_indices.append(dest_node_idx)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sankey_values.append(value)

Â  Â  Â  Â  Â  Â  # Check for data sufficiency for Sankey
Â  Â  Â  Â  Â  Â  if not sankey_values or sum(sankey_values) == 0 or not display_sankey:
Â  Â  Â  Â  Â  Â  Â  Â  st.info(f"Not enough data or zero total MQ to draw Sankey chart for {selected_date_str}.")
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  fig = go.Figure(data=[go.Sankey(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  node=dict(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pad=25, # Increased padding
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  thickness=20,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  line=dict(color="black", width=0.5),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label=sankey_node_labels,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color=node_colors # Use the dynamic list of colors
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  link=dict(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  source=sankey_sources_indices,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target=sankey_targets_indices,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value=sankey_values,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  )])
Â  Â  Â  Â  Â  Â  Â  Â  fig.update_layout(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  title_text=f"Energy Flow for {selected_date_str}",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  font_size=10,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  height=600 # Adjust height if needed
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  st.plotly_chart(fig, use_container_width=True)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.warning(f"Cannot generate Sankey: MQ or WESM data missing/invalid for {selected_date_str}.")

Â  Â  else: # if data.empty
Â  Â  Â  Â  st.warning(f"No data available for selected date: {selected_date_str}.")
